---
title: "Exploring Mac Miller's Discography with Spotify API"
author: "Collin Smith"
date: '2022-05-19'
---

```{r chunk-setup}
knitr::opts_chunk$set(fig.align = "center")
ggplot2::theme_set(ggplot2::theme_minimal())
```


# Welcome!

Hello, and welcome to my very first Markdown publication. 
The vast majority of my time spent with R has been for university courses, so
I thought it would be a good change of pace to apply the skills I've learned
to a personal project. I have learned a great deal from books like 
Hadley Wickham's [R for Data Science](https://r4ds.had.co.nz/), as well as 
tutorials, articles, and markdown pages from sites such as 
[RPubs](https://rpubs.com/), [R-bloggers](https://www.r-bloggers.com/), 
and [Towards Data Science](https://towardsdatascience.com/). 
My hope is that this project can in turn be used to help someone else down 
the road, as others have helped me.

In this project, we will be exploring how to use Spotify's API and 
the **spotifyr** package to access data about a particular artists discography. 
We'll also be utilizing the **geniusr** package to retrieve lyrics for 
songs, allowing for sentiment to be explored and visualized, and doing our best
to apply a clustering algorithm to the discography.

# Spotify API Credentials

To begin, we will first need to head over to the 
[Spotify for Developers](https://developer.spotify.com/dashboard/) page, 
where we will be registering an application to obtain an API key. Once you've 
logged in, select "Create an App" and fill out the required fields. Completing 
this will give you access to two important fields: your **client id** and 
your **client secret** (or API key). These fields will be used to let the
API know who is accessing it and that you have proper authentication. 
To get started, first install the **spotifyr** package if you don't already
have it.

```{r pkg-install, eval = F, include = T}
install.packages("spotifyr")
```

Next, we can use the following code to pass out authentication credentials
to the API, giving us access.

```{r auth-example, eval = F, include = T}
Sys.setenv(SPOTIFY_CLIENT_ID = 'your client id')
Sys.setenv(SPOTIFY_CLIENT_SECRET = 'your client secret')
access_token <- get_spotify_access_token()
```

```{r auth-actual, eval = T, echo = F}
source('auth_func.R')
authenticate()
```

# Gathering the Data

Now that you are authenticated with the API, we can begin using the 
**spotifyr** package's functions to retrieve information.
In this project, we will be analyzing Mac Miller's discography and exploring 
how his sound changed throughout his career. To get information regarding 
a single artist's discography, we can use the `get_artist_audio_features()` 
function. The function will return a dataframe containing information about all 
of the artists' music that is hosted on Spotify. The function takes many 
possible arguments, but for the sake of this project, we only need to pass in 
one: the name of the artist for which we wish to get information.

```{r get-data, echo = T}
library(spotifyr)
mm_data <- get_artist_audio_features(artist = "Mac Miller")
```

To check that this function performed as expected, let's take a very quick
glance at the returned dataframe.

```{r data-check, echo = T}
colnames(mm_data)
unique(mm_data$album_name)
head(mm_data$track_name, 15)
dim(mm_data)
```

Excellent! The returned dataframe contains ``r dim(mm_data)[1]`` observations,
or in this case songs, and each observation has ``r dim(mm_data)[2]`` variables.

# Checking the Data

We can see from the `unique(mm_data$album_name)` function that the albums are
listed in order of upload date, with Faces being the most recent album added
to Mac's Spotify page. While this may seem handy, it is important to note that
the order in which albums are uploaded to Spotify is not always the same order
that the albums were released. We can observe this by taking a look at the
`album_release_date` variable.

```{r libs, message = F}
library(tidyverse)
library(plotly)
```

```{r album-dates, echo = T}
mm_data %>% 
  select(album_name, album_release_date) %>%
  distinct()
```

This readout implies that Faces is the most recent album to release. However,
by checking Mac's 
[discography](https://en.wikipedia.org/wiki/Mac_Miller_discography), we can see
that Faces was actually released as a mixtape back in 2014, much earlier than
the variable from Spotify's data would suggest. Since this project involves 
analyzing how Mac's music changed throughout the duration of his career, it is
important to have accurate ordering of dates associated with the albums.

## Webscraping

To remedy this, we can use some quick web scraping to pull the release dates 
from the wiki page and amend the data.

```{r wiki-scrape, message = F}
# run install.packages('rvest') if you don't have this package already
library(rvest)
url <- "https://en.wikipedia.org/wiki/Mac_Miller_discography"
wp <- read_html(url)
rel_dates <- html_nodes(
  wp, "th i , .plainrowheaders th+ td li:nth-child(1) , th i a") %>%
  html_text()
```

Now, the above code may look a little intimidating if you are new to
webscraping. That's okay, it looks much scarier than it really is. The
`read_html()` function simply reads the page's html code and stores it as a 
list in your R environment. Then, we need to tell R what parts of the webpage
we want extracted. To do this, I used the 
[SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en) extension for Chrome. Using the tool makes webscraping
very simple, you just highlight the elements you wish to capture and the tool
will give you the CSS selector for it. That is how the arguments you see in the
`html_nodes()` function were found. Once you've identified the nodes, pass the
results to the `html_text()` function and voila! You know have text from a
website stored right in your R environment.

Let's check out what our scraping resulted in:

```{r chk-scrape}
head(rel_dates, 20)
```

### Cleaning the scraped data

While that looks pretty good, you can see that the album titles are listed
twice, and the release dates could be formatted a little nicer. Let's fix that
up to a nicer format.

```{r scrape-cleaning}
# Remove duplicates and format into dataframe for manipulation
rel_dates <- matrix(
  unique(rel_dates), ncol = 2, byrow = T) %>%
  as.data.frame()

# Filter out any works that aren't hosted on Spotify
rel_dates <- rel_dates %>% filter(
  V1 %>% tolower() %in% (unique(mm_data$album_name) %>% 
                    gsub("( \\().*", "", .) %>%
                    tolower()))

# Cleaning date text
rel_dates$V2 <- gsub("(?:Released: )", "", rel_dates$V2)
rel_dates$V2 <- gsub(".{4}$", "", rel_dates$V2)

# Converts textual dates to date type object
rel_dates$V2 <- lubridate::parse_date_time(
  rel_dates$V2, orders = "mdy") %>%
  lubridate::as_date()

# Check results to ensure they look as expected
rel_dates
```

## Prepping for Merge

Now our release dates are in a more workable format. However, before we merge
the two datasets, let's first take one more look at the album names in our 
main dataframe, `mm_data`. 

```{r album-name-check}
unique(mm_data$album_name)
```

We see from this readout that many albums contain multiple editions, such as
deluxe releases, remasters, or commentary bonuses. To prevent our analysis from
being biased towards those repeated works, we should selectively filter out 
albums that are listed multiple times. Firstly, the commentary version of
Blue Slide Park will be omitted. Next, for any album that has a deluxe release,
we will keep only the deluxe release, dropping the original album from the
dataset. Lastly, we will rename 
*Best Day Ever (5th Anniversary Remastered Edition)* and
*Macadelic (Remastered Edition)*. 
This will help us when merging the datasets.

```{r pre-merge-cleaning}
# Shortening 'Best Day Ever' album name for merging
mm_data$album_name[
  mm_data$album_name == 
  "Best Day Ever (5th Anniversary Remastered Edition)"] = "Best Day Ever"

# Dropping '(Remastered Edition)' from Macadelic
mm_data$album_name[
  mm_data$album_name == 
  "Macadelic (Remastered Edition)"] = "Macadelic"

# Drop any non-deluxe editions of albums that have deluxe editions
# Note that Blue Slide Park's additional versions were also dropped
# Live From London was dropped as it only included already present songs
mm_data <- filter(mm_data, !(album_name %in% c(
  "Circles", 
  "Watching Movies with the Sound Off", 
  "K.I.D.S.",
  "Mac Miller : Live From London (With The Internet)",
  "Blue Slide Park (Commentary Version)",
  "Blue Slide Park (Edited Version)")))

# Adding " (Deluxe)" onto album names in true release date set for merging
for(i in c(2, 6, 8)){
  if(i == 2){
    rel_dates$V1[i] = str_c(rel_dates$V1[i], " (Deluxe Edition)")}
  else
    rel_dates$V1[i] = str_c(rel_dates$V1[i], " (Deluxe)")}

# Adjusting Capitalization of "Live from Space" to match mm_data$album_name
rel_dates$V1[rel_dates$V1 == "Live from Space"] = "Live From Space"
```

## Merging the Data

Now that our extra versions have been dropped from the data, we can finally
merge our two datasets to attach the accurate release dates.

```{r date-combine}
# Performing the merge of the two datasets
mm_data <- left_join(mm_data, rel_dates,
                     by = c("album_name" = "V1"))
mm_data <- mm_data %>% rename("true_rel_date" = "V2")
```

With the merge complete, let's take a look at the differences between the
original `album_release_date` column and our new `true_rel_date` column.

```{r rel-date-comp}
select(mm_data, album_release_date, album_name, true_rel_date) %>%
  unique()
```

Excellent! Now that we have each album's true release date, we can go ahead and
drop the old variable `album_release_date` and rename our new variable to take
its place.

```{r rel-date-swap}
mm_data <- select(mm_data, -album_release_date) %>% 
  rename(album_release_date = true_rel_date)
```

## Filtering the Data

### Handling Duplicates

Before we head into the next step in our analysis, let's first make sure that we
don't have multiple entries of any tracks.

```{r dupe-check}
mm_data$track_name[duplicated(mm_data$track_name)]
```

Good thing we checked! 27 duplicate entries is no joke, so let's figure out how
this happened. Familiarity with Spotify and Mac's library leads me to initially
suspect that these tracks appear on both an explicit and clean versions of
their respective albums. We can check this assumption rather quickly, so let's 
do so.

```{r dupe-investigation}
mm_data %>% 
  filter(
    track_name %in% (mm_data$track_name[duplicated(mm_data$track_name)])) %>%
  select(track_name, album_name, explicit) %>%
  arrange(album_name)
```

As expected, it looks like the duplicate entries stem from clean editions of
albums. To handle this, we can first double-check that aside from the clean
albums, every album in the dataset contains at least one explicit song. If so,
then we can group the observations by album and simply drop any album that
contains no explicit tracks.

```{r explicit-check}
# note we use album_id here because it is unique for explicit and clean versions
mm_data %>%
  group_by(album_id, album_name) %>%
  count(explicit == TRUE) %>%
  arrange(album_name)
```

We can see here that the only albums with two different entries for **album_id**
are *GO:OD AM* and *The Divine Feminine*. These entries represent the explicit
and clean editions of the albums. To handle this, we can simply filter out
any entry that matches the **album_id** value of the clean editions of these
albums.

```{r}
mm_data <- mm_data %>%
  filter(!album_id %in% c("6lEUoXk2C9IpUWPd4caiNE", "4gtXD5SL0yysd1eRIrDpnZ"))
```


## Variable Selection

Now that our release date and duplicate entry issues have been solved, let's 
take a look at which variables we'd like to keep, and which ones we can exclude 
moving forward.

```{r df-name-list}
print(names(mm_data))
```

As we can see, there are quite a few variables in the set. To get an idea of
what each variable holds, we can use *tidyverse*'s `glimpse()` function.

```{r data-glimpse}
glimpse(mm_data)
```

Wow! That's a lot of info. To make things a little simpler, we can refer to
[Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features)
to get a better idea of what these variables represent. Some variables are 
rather self-explanatory, such as `artist_name`, `track_name`, `album_name`, and
`duration_ms`. For this analysis, we want to keep identifying information such
as a tracks name, the album it came from, and the release date. The other
variables we'll want to keep are measures about the songs sonic signature. These
measures include `danceability`, `energy`, `loudness`, `speechiness`,
`acousticness`, `instrumentalness`, `liveness`, and `valence`. These are metrics
provided by Spotify that give quantitative measures of a track's audio
characteristics. More information on these metrics and how they are derived can
be found at [Spotify's API documentation](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features).
Other variables we'll want to keep are `key`, `mode`, `tempo`, `time_signature`,
`duration_ms`, and `explicit`. These variables provide more information about
the composition of the song.

Now that we've identified the variables we want to keep in our working data, we
can go ahead and create a filtered version of the full data to move forward
with. We can also take this opportunity to reorder our variables into more 
organized groups.

```{r select-variables}
df <- mm_data %>% select(
  # identifying information
  track_name,
  artist_name,
  album_name,
  album_release_date,
  # spotify provided quantitative measures
  acousticness,
  danceability,
  energy,
  instrumentalness,
  liveness,
  loudness,
  speechiness,
  valence,
  # composition information
  duration_ms,
  explicit,
  key,
  mode,
  tempo,
  time_signature
)
```

```{r format-cleaning}
# quickly formatting key, mode, and time signature as factors
df <- df %>% mutate(across(c(key, mode, time_signature), as.factor))
```

# Exploratory Data Analysis (EDA)

With the data sorted and filtered to only include relevant variables, we are
now ready to begin using statistical summaries and creating visualizations
to glean insights from. We will be exploring the data to discover patterns, 
identify anomalies (or outliers), and to make some informed observations that
will help us to better understand the dataset.

## Statistical Summary

We'll start our analysis by looking at a basic statistical summary of the
quantitative variables in our dataset. We can easily find what variables to 
include by using a `select()` statement.

```{r stat-summ}
df %>% 
  select(where(is.numeric)) %>%
  summary()
```

These values tell us some great cursory information about the data.

### Some observations:

* **acousticness** has the widest range of all Spotify's metrics, but the mean
and 3rd quartile suggest the max may be an anomaly
* **danceability** and **energy** have relatively similar summaries, suggesting
possible correlation between the two. Values tend to trend upwards, indicating
the minimum value in both of these variables may be outliers (potentially even
the same track? worth investigating)
* **instrumentalness** doesn't contain any values > 0.5, Spotify's threshold 
intended to represent instrumental tracks, as per their documentation linked
above. This suggests the discography does not contain any purely instrumental
tracks
* **liveness** having a max of ``r max(df$liveness)`` suggests Spotify is 
confident that at least one track was performed live (documentation lists 0.8
as the likelihood threshold). This max is very far from the rest of the measures
for **liveness**, indicating a likely outlier
* **loudness**, measured in decibels (dB) also has a relatively wide range, 
with all values < 0. Spotify lists typical range as falling between -60 and 0, 
suggesting Mac's music trends towards the upper side of this traditional range
* **speechiness** tends to be lower than Spotify's typical value range for rap
music (0.33 - 0.66 as per documentation). This suggests Mac's tracks have more
sections that do not contain vocals in them. Investigating this on a per-album
basis could yield interesting findings
* **valence** sees a wide range of values, with the mean and median falling just
under the halfway point between the min and max. However, the 3rd quartile value
tells us that the max value is likely an anomaly
* **duration_ms** seems to hold a rather tight distribution for the most part, 
with both the min and the max values seemingly pretty distant from the typical
values in the variable
* **tempo** holds some surprising values. The mean and median suggest that ~120
is Mac's typical tempo, which is higher than the 
[average hip-hop tempo range](https://www.izotope.com/en/learn/using-different-tempos-to-make-beats-for-different-genres.html).
The linked source offers that typically, the higher the beats per minute (BPM),
or tempo, the more energy and uplifting a track is. Knowing this, it would be 
interesting to investigate the relationship between **tempo**, **energy**,
**valence**, and **danceability**. I'd expect, at the very least, a weak 
positive correlation between all those variables

## Visualizations

### Per Album Plots

This section will focus on some simple but important plots, mostly involving 
counts and frequencies of measures. This will give a good overview of our data 
at a high level before we delve into specifics and multivariate interactions.

```{r album-track-counts}
album_palette = c(
  "K.I.D.S. (Deluxe)" = "#387228",
  "Best Day Ever" = "#C315AA",
  "Blue Slide Park" = "#3540F2",
  "Macadelic" = "#767092",
  "Watching Movies with the Sound Off (Deluxe Edition)" = "#DA252A",
  "Live From Space" = "#FE675C",
  "Faces" = "#FDBB1E",
  "GO:OD AM" = "#A2A2A2",
  "The Divine Feminine" = "#DDC1BE",
  "Swimming" = "#668099",
  "Circles (Deluxe)" = "#464646"
  )

df %>% 
  group_by(
    album_name,
    album_release_date) %>%
  tally() %>%
  ggplot(
    aes(
      x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date), 
      y = n,
      fill = album_name
    )
  ) +
  geom_col() +
  geom_text(
    aes(label = n), 
    vjust = -0.2, 
    size = 3.5
  ) +
  scale_y_continuous(
    limits = c(0, 26)
  ) +
  labs(
    x = "", 
    y = "",
    title = "Tracks Per Mac Miller Album",
    subtitle = "Ordered by Release Date"
  ) +
  scale_fill_manual(
    values = album_palette
  ) +
  theme(
    legend.position = "none"
  )
```

From this plot we can see that Mac's earlier albums tended to have a couple
more songs than his later releases, with *Faces* being the outlier of the
discography as a whole. This could partly be due to *Faces* originally being
released as a mixtape rather than a formal album, so perhaps it did not go
through the same revision processes that an album might see before release.

#### Duration {.tabset .tabset-fade}

Let's also take a look at track duration trends for each album, as well as each
album's total runtime.

##### Overview

```{r track-duration-by-album}
df %>%
  group_by(album_name) %>%
  ggplot(aes(
    x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date),
    y = duration_ms,
    fill = album_name)) +
  geom_boxplot() +
  geom_point(alpha = 0.4, shape = "diamond") +
  labs(x = "",
       y = "Track Duration (ms)",
       title = "Track Duration by Album") +
  scale_fill_manual(values = album_palette) +
  theme(legend.position = "none")
```

This plot tells us that even though they typically had fewer tracks on them, 
Mac's later albums contained tracks that, on average, were longer than tracks on
earlier albums. This can almost be thought of as a focus on "quality over
quantity" when it comes to the later albums. Furthermore, the plot shows that
earlier albums had less variation in track duration, while later albums saw
more variety. It is interesting to see how *The Divine Feminine*, the album
with the fewest tracks, not only contains the longest track in the dataset, but
also two tracks that are significantly longer than the rest of the album. This
could very well be an example of careful song selection to help each album
maintain a relatively similar total runtime. We'll examine that below.

```{r album-runtimes}
df %>%
  group_by(album_name) %>%
  summarise(album_name, 
            runtime = sum(duration_ms), 
            album_release_date,
            .groups = "keep") %>%
  ggplot(aes(
    x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date),
    y = runtime,
    fill = album_name)) +
  geom_col() +
  labs(x = "",
       y = "Runtime (ms)",
       title = "Total Album Runtimes") +
  scale_fill_manual(values = album_palette) +
  theme(legend.position = "none")
```

By comparing this plot with the information about each album's number of tracks,
we can see that there is a very clear correlation between number of tracks and
album runtime. For example, even though *K.I.D.S.* has a lower average track
duration than *Swimming*, the total runtime is still longer for *K.I.D.S.*, due
to the difference in track count. Generally, longer albums are subject to a bit
more criticism, as too long of a runtime can start to make the listener become
disinterested if the music doesn't provide enough variation. Knowing this, it
again makes sense that *Faces* has such a higher runtime than any other work, as
it's original release as a mixtape meant that it didn't go through the same
revisions and polishing processes that formal albums do. This runtime plot also
confirms our previous theory of Mac's later albums revolving more around the
substance of each individual track rather than making a longer, less focused 
album. We can also see from the plot that the concept of keeping longer songs
on *The Divine Feminine* does not really appear to have had a substantial 
impact on the album's total runtime, as it is still significantly shorter than
all other works.

```{r album-trends, results = 'hide', fig.show = 'hold', message = F}
album_trends <- df %>%
  group_by(album_name) %>%
  summarise(
    album_name,
    album_release_date,
    average_track_length = mean(duration_ms),
    track_count = n(),
    .groups = "keep") %>%
  ggplot(
    aes(
      x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date),
    )
  )

avg_track_len_plot <- album_trends +
  geom_line(aes(y = average_track_length, group = 1)) +
  geom_point(aes(y = average_track_length)) +
  geom_smooth(
    aes(y = average_track_length, group = 1), 
    method = "lm",
    formula = y ~ x,
    alpha = 0.5,
    lty = "dotted",
    se = FALSE) +
  labs(x = "",
       y = "Average Duration (ms)",
       title = "Average Track Duration Trend") +
  scale_y_continuous(
    breaks = c(2e+05, 2.4e+05, 2.8e+05, 3.2e+05),
    labels = c("200K", "240K", "280K", "320K"))

total_tracks_plot <- album_trends +
  geom_line(aes(y = track_count, group = 1)) +
  geom_point(aes(y = track_count)) +
  geom_smooth(
    aes(y = track_count, group = 1), 
    method = "lm",
    formula = y ~ x,
    alpha = 0.5,
    lty = "dotted",
    se = FALSE) +
  labs(x = "",
       y = "Tracks Per Album",
       title = "Tracks per Album Trend")

avg_track_len_plot
total_tracks_plot

```

While not too severe, these plots reveal that over the course of his career,
Mac's albums tended to contain less songs, but those songs were of longer
duration.

##### Album-Specific

```{r track-durations-by-album, results = 'hide', fig.keep = 'all'}
album_names <- arrange(df, df$album_release_date) %>% 
  .$album_name %>% 
  unique()

figures = list()

for(i in album_names){
  
  figures[[i]] <- df %>%
    filter(album_name == i) %>%
    ggplot(
      aes(x = reorder(fct_inorder(track_name), desc(fct_inorder(track_name))), 
          y = duration_ms, fill = i)) +
    geom_col() +
    labs(x = "",
         y = "Track Duration (ms)",
         title = i) +
    scale_y_continuous(limits = c(0, 5.5e+05)) +
    coord_flip() +
    #ggthemes::theme_clean() +
    scale_fill_manual(values = album_palette) +
    theme(legend.position = "none",
          plot.title.position = "plot")
  
}

aligned_figs <- cowplot::align_plots(plotlist = figures, align = "v")

lapply(aligned_figs, function(x) {cowplot::ggdraw(x)})
```

#### Explicitness

Let's take a quick look at the proportion of explicit and non-explicit (clean)
tracks on each album.

```{r explicit-overview-plot}
exp_plot <- df %>%
  group_by(album_name, album_release_date) %>%
  count(explicit) %>%
  ggplot(
    aes(
      x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date),
      y = n,
      fill = explicit
    )
  ) + 
  geom_col(position = "fill", color = "black", alpha = 0.8, width = 0.95) +
  labs(x = "",
       y = "",
       title = "Proportion of Explicit Tracks",
       subtitle = "Per Album, ordered by Release Date",
       fill = "Explicit") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = c("FALSE" = "lightgreen", "TRUE" = "coral")
  ) +
  theme(legend.position = c(0.725, 1.1),
        legend.direction = "horizontal",
        legend.box.background = element_rect(color = "lightgrey"))

exp_table <- df %>%
  group_by(album_name) %>%
  summarise(n_tracks = n(),
            n_explicit = sum(explicit == TRUE),
            prop_explicit = round(n_explicit / n_tracks, 2),
            album_release_date,
            .groups = "keep") %>%
  arrange(album_release_date) %>%
  distinct() %>%
  select("Album Name" = album_name,
         "Track Count" = n_tracks,
         "Explicit Tracks" = n_explicit,
         "Prop. Explicit" = prop_explicit)

exp_plot
exp_table
```

Some observations from this plot and table:

* All but one of the albums contained a proportion of explicit tracks >= 0.8
* *Circles*, Mac's last album is the only work that contains more clean
tracks than explicit tracks

#### Acousticness

Per Spotify's 
[documentation](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features),
**acousticness** is "*A confidence measure from 0.0 to 1.0 of whether or not 
the track is acoustic. 1.0 represents high confidence that the track is 
acoustic. According to 
[Wikipedia](https://en.wikipedia.org/wiki/Acoustic_music),
acoustic music is generally thought of as music that primary features
features that produce sound through physical properties, as opposed to electric
or digital amplification (think grand piano versus digital keyboard). 


```{r acousticness-explore, results = 'hide', fig.show = 'hold'}
df %>% 
  group_by(album_name, album_release_date) %>%
  ggplot(
    aes(
      x = stringr::str_wrap(album_name, 9) %>% reorder(album_release_date),
      y = acousticness,
      fill = album_name
    )
  ) +
  geom_boxplot() +
  labs(x = "",
       y = "",
       title = "Summary of Acousticness",
       subtitle = "Per Album, ordered by Release Date") +
  theme(legend.position = "none") +
  scale_fill_manual(values = album_palette)

df %>%
  group_by(album_name, album_release_date) %>%
  ggplot(
    aes(
      y = stringr::str_wrap(album_name, 28) %>% reorder(album_release_date),
      x = acousticness,
      fill = album_name
    )
  ) +
  ggridges::geom_density_ridges2() +
  labs(x = "",
       y = "",
       title = "Density of Acousticness Measures",
       subtitle = "Per Album") +
  scale_fill_manual(values = album_palette) +
  theme(legend.position = "none")

df %>%
  group_by(album_name, album_release_date) %>%
  summarise(
    avg_acousticness = mean(acousticness)
  ) %>%
  ggplot(aes(x = album_release_date, y = avg_acousticness)) +
  geom_line(color = "lightblue", size = 1.5) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = album_name), force = ) +
  labs(y = "Acousticness",
       x = "Album Release Year",
       title = "Average Acousticness Per Album",
       subtitle = "Ordered by Release Date")
```

From these plots we can see a clear trend of increasing **acousticness** towards
the later works of Mac's career. We can also see greater variation in the 
values of later albums, suggesting the possibility of more distinct sonic 
changes from album to album later in his career.

### Measure Distributions

This section will focus on displaying some simple yet informative information
regarding Spotify's quantitative metrics:

* **acousticness**
* **danceability**
* **energy**
* **instrumentalness**
* **liveness**
* **speechiness**
* **valence**

```{r spot-measure-density}
measures <- c(
  "acousticness",
  "danceability",
  "energy",
  "instrumentalness",
  "liveness",
  "speechiness",
  "valence"
)

df %>%
  select(all_of(measures)) %>%
  gather() %>%
  mutate(key = factor(key)) %>%
  filter(value > 0.1) %>%
  ggplot(aes(x = value, color = key)) +
  geom_density(size = 1.25) +
  labs(x = "Value",
       y = "Density",
       color = "Measure",
       title = "Spotify Measure Density Plot") +
  scale_color_brewer(type = "qual", palette = 7)
```

From this plot, we can see that **danceability** and **energy** seem to have
very similar density curves. It is definitely worth investigating if there is
any correlation between those two measures. Additionally, within the code to
construct the plot, you'll notice there is a `filter()` statement to set the
lower limit of the values to 0.1. This was done to exclude the enormous amount
of **instrumentalness** observations that lie between 0 and 0.1, which stretched
the y-axis by far too much for the rest of the density curves to be observed.

### Multivariate Plots

Here we will be investigating some of the questions posed above by looking at
the interaction between specific variables.

#### 